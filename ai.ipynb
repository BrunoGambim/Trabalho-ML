{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data['Ano'] = data['Data'].dt.year\n",
    "data['Mes'] = data['Data'].dt.month\n",
    "data['Dia'] = data['Data'].dt.day\n",
    "data.drop('Data', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "enCodigoer = OneHotEncoder(sparse=False)\n",
    "enCodigoed_data = enCodigoer.fit_transform(data[['Codigo']])\n",
    "enCodigoed_data_df = pd.DataFrame(enCodigoed_data, columns=enCodigoer.get_feature_names_out(['Codigo']))\n",
    "\n",
    "data = pd.concat([data.drop(['Codigo'], axis=1), enCodigoed_data_df], axis=1)\n",
    "#data = pd.concat([data.drop(['Cidade', 'Codigo'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Cidade', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "data[['Pressao Maxima','Pressao Maxima','Temperatura Maxima','Temperatura Minima','Temperatura Orvalho Maxima','Temperatura Orvalho Minima','Umidade Minima',\n",
    "      'Umidade Maxima','Precipitacao Total', 'Pressao Media', 'Temperatura Media', 'Temperatura Orvalho Media', 'Umidade Media', 'Direcao Vento',\n",
    "      'Rajada Maxima de Vento','Vento Velocidade Media', 'Latitude', 'Longitude', 'Ano', 'Mes', 'Dia']] = scaler.fit_transform(\n",
    "          data[['Pressao Maxima','Pressao Maxima','Temperatura Maxima','Temperatura Minima','Temperatura Orvalho Maxima','Temperatura Orvalho Minima',\n",
    "                'Umidade Minima', 'Umidade Maxima','Precipitacao Total', 'Pressao Media', 'Temperatura Media', 'Temperatura Orvalho Media', 'Umidade Media', \n",
    "                'Direcao Vento', 'Rajada Maxima de Vento', 'Vento Velocidade Media', 'Latitude', 'Longitude', 'Ano', 'Mes', 'Dia']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Precipitacao Total', 'Pressao Media', 'Pressao Maxima',\n",
      "       'Pressao Minima', 'Temperatura Media', 'Temperatura Orvalho Media',\n",
      "       'Temperatura Maxima', 'Temperatura Minima',\n",
      "       'Temperatura Orvalho Maxima', 'Temperatura Orvalho Minima',\n",
      "       'Umidade Maxima', 'Umidade Minima', 'Umidade Media', 'Direcao Vento',\n",
      "       'Rajada Maxima de Vento', 'Vento Velocidade Media', 'Latitude',\n",
      "       'Longitude', 'Ano', 'Mes', 'Dia', 'Codigo_A801', 'Codigo_A802',\n",
      "       'Codigo_A803', 'Codigo_A804', 'Codigo_A805', 'Codigo_A808',\n",
      "       'Codigo_A809', 'Codigo_A810', 'Codigo_A811', 'Codigo_A812',\n",
      "       'Codigo_A813', 'Codigo_A826', 'Codigo_A827', 'Codigo_A828',\n",
      "       'Codigo_A829', 'Codigo_A830', 'Codigo_A831', 'Codigo_A832',\n",
      "       'Codigo_A833', 'Codigo_A834', 'Codigo_A836', 'Codigo_A837',\n",
      "       'Codigo_A838', 'Codigo_A839', 'Codigo_A840', 'Codigo_A844',\n",
      "       'Codigo_A852', 'Codigo_A853', 'Codigo_A854', 'Codigo_A856',\n",
      "       'Codigo_A878', 'Codigo_A879', 'Codigo_A880', 'Codigo_A881',\n",
      "       'Codigo_A882', 'Codigo_A883', 'Codigo_A884', 'Codigo_A886',\n",
      "       'Codigo_A887', 'Codigo_A889', 'Codigo_A893', 'Codigo_A894',\n",
      "       'Codigo_A897', 'Codigo_A899', 'Codigo_B807'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('Vai Chover Amanha', axis=1)\n",
    "y = data['Vai Chover Amanha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(contamination=0.1)\n",
    "yhat = lof.fit_predict(X)\n",
    "mask = yhat != -1\n",
    "X = X[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nao    113909\n",
      "Sim    113909\n",
      "Name: Vai Chover Amanha, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "majority_class_data = train_data[train_data['Vai Chover Amanha'] == 'Nao']\n",
    "miNaority_class_data = train_data[train_data['Vai Chover Amanha'] == 'Sim']\n",
    "upsampled_miNaority_class = resample(miNaority_class_data, replace=True, n_samples=len(majority_class_data))\n",
    "train_data = pd.concat([majority_class_data, upsampled_miNaority_class], axis=0)\n",
    "\n",
    "X_train = train_data.drop('Vai Chover Amanha', axis=1)\n",
    "y_train = train_data['Vai Chover Amanha']\n",
    "\n",
    "print(train_data['Vai Chover Amanha'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp(data_x, data_y):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(50,100,100, 50), activation='relu', max_iter=50, random_state=42)\n",
    "    mlp.fit(data_x, data_y)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt(data_x, data_y):\n",
    "    dt = DecisionTreeClassifier(splitter='best', max_depth=None, criterion='gini')\n",
    "    dt.fit(data_x, data_y)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf(data_x, data_y):\n",
    "    rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_scikit(model, data_x, data_y):\n",
    "    print(\"plot_result_scikit\")\n",
    "    y_pred = model.predict(data_x)\n",
    "    accuracy = accuracy_score(data_y, y_pred),\n",
    "    #mse = mean_squared_error(y_test, y_pred)\n",
    "    FP = np.sum((y_pred == 'Sim') & (data_y == 'Nao'))\n",
    "    FN = np.sum((y_pred == 'Nao') & (data_y == 'Sim'))\n",
    "    VP = np.sum((y_pred == 'Sim') & (data_y == 'Sim'))\n",
    "    VN = np.sum((y_pred == 'Nao') & (data_y == 'Nao'))\n",
    "\n",
    "    print(f\"Accuracy: {accuracy} | FP:{FP} | FN:{FN} | VP:{VP} | VN:{VN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot_result_scikit\n",
      "Accuracy: (0.696187307412057,) | FP:30276 | FN:38938 | VP:74971 | VN:83633\n",
      "plot_result_scikit\n",
      "Accuracy: (0.7119630109493686,) | FP:7606 | FN:3732 | VP:7148 | VN:20877\n"
     ]
    }
   ],
   "source": [
    "scikit_model = get_mlp(X_train, y_train)\n",
    "plot_result_scikit(scikit_model, X_train,y_train) \n",
    "plot_result_scikit(scikit_model, X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
